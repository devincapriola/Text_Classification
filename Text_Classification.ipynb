{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "29M8tf1GvYkI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -nc https://lazyprogrammer.me/course_files/spam.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOfhM7byQCEt",
        "outputId": "51a1e60e-ab8f-42b5-f843-276a66ba914e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File ‘spam.csv’ already there; not retrieving.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head spam.csv"
      ],
      "metadata": {
        "id": "QvNoRpbhVio2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e3bee26-e338-4f08-b521-f3ada2fa1c78"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "v1,v2,,,\r\n",
            "ham,\"Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\",,,\r\n",
            "ham,Ok lar... Joking wif u oni...,,,\r\n",
            "spam,Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's,,,\r\n",
            "ham,U dun say so early hor... U c already then say...,,,\r\n",
            "ham,\"Nah I don't think he goes to usf, he lives around here though\",,,\r\n",
            "spam,\"FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, �1.50 to rcv\",,,\r\n",
            "ham,Even my brother is not like to speak with me. They treat me like aids patent.,,,\r\n",
            "ham,As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune,,,\r\n",
            "spam,WINNER!! As a valued network customer you have been selected to receivea �900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.,,,\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('spam.csv', encoding='ISO-8859-1')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FH00Li8J2gwG",
        "outputId": "ed42605d-fb84-48f6-afc1-941057ab5087"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     v1                                                 v2 Unnamed: 2  \\\n",
              "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
              "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
              "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
              "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
              "\n",
              "  Unnamed: 3 Unnamed: 4  \n",
              "0        NaN        NaN  \n",
              "1        NaN        NaN  \n",
              "2        NaN        NaN  \n",
              "3        NaN        NaN  \n",
              "4        NaN        NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a27854c5-90a2-41da-99bc-54cba21084af\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a27854c5-90a2-41da-99bc-54cba21084af')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a27854c5-90a2-41da-99bc-54cba21084af button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a27854c5-90a2-41da-99bc-54cba21084af');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# drop unnecessary columns\n",
        "df = df.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ZKAFRTpY2p_i",
        "outputId": "8ae08cf9-acdb-450d-b35d-61bcecf9ce9f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     v1                                                 v2\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-72f8806a-71be-4a68-a9b2-1aba746fa0a9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72f8806a-71be-4a68-a9b2-1aba746fa0a9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-72f8806a-71be-4a68-a9b2-1aba746fa0a9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-72f8806a-71be-4a68-a9b2-1aba746fa0a9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rename columns to something better\n",
        "df.columns = ['labels', 'data']\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WAktQp_E23yZ",
        "outputId": "172cfbad-7051-4705-ac90-c83fd4a1a1d2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  labels                                               data\n",
              "0    ham  Go until jurong point, crazy.. Available only ...\n",
              "1    ham                      Ok lar... Joking wif u oni...\n",
              "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3    ham  U dun say so early hor... U c already then say...\n",
              "4    ham  Nah I don't think he goes to usf, he lives aro..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c52e463-08b6-4bcd-937d-ffc07197a0a8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c52e463-08b6-4bcd-937d-ffc07197a0a8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3c52e463-08b6-4bcd-937d-ffc07197a0a8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3c52e463-08b6-4bcd-937d-ffc07197a0a8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create binary labels\n",
        "df['b_labels'] = df['labels'].map({'ham':0, 'spam':1})"
      ],
      "metadata": {
        "id": "EerUx0fX3KbC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_test = train_test_split(df, test_size=0.33)\n",
        "df_train.shape, df_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeYOAAVw3P4V",
        "outputId": "e2dc541f-4e8d-4714-8e72-f18670066728"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3733, 3), (1839, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 0 = padding\n",
        "idx = 1\n",
        "word2idx = {'<PAD>': 0}"
      ],
      "metadata": {
        "id": "EdkBnJx33i43"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You could also use gensim or spacy for tokenization\n",
        "# but I wanted to keep it simple\n",
        "for i, row in df_train.iterrows():\n",
        "    tokens = row['data'].lower().split() # simple tokenization\n",
        "    for token in tokens:\n",
        "        if token not in word2idx:\n",
        "            word2idx[token] = idx\n",
        "            idx += 1"
      ],
      "metadata": {
        "id": "w6H1Oiln4SwH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word2idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WUqAcdY4UjQ",
        "outputId": "43b738bd-41dc-47ca-dced-665095588cbc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<PAD>': 0,\n",
              " \"it's\": 1,\n",
              " 'wylie,': 2,\n",
              " 'you': 3,\n",
              " 'in': 4,\n",
              " 'tampa': 5,\n",
              " 'or': 6,\n",
              " 'sarasota?': 7,\n",
              " 'ummmmmaah': 8,\n",
              " 'many': 9,\n",
              " 'happy': 10,\n",
              " 'returns': 11,\n",
              " 'of': 12,\n",
              " 'd': 13,\n",
              " 'day': 14,\n",
              " 'my': 15,\n",
              " 'dear': 16,\n",
              " 'sweet': 17,\n",
              " 'heart..': 18,\n",
              " 'birthday': 19,\n",
              " 'hey!': 20,\n",
              " \"there's\": 21,\n",
              " 'veggie': 22,\n",
              " 'pizza...': 23,\n",
              " ':/': 24,\n",
              " 'ìï': 25,\n",
              " 'got': 26,\n",
              " 'wat': 27,\n",
              " 'to': 28,\n",
              " 'buy': 29,\n",
              " 'tell': 30,\n",
              " 'us': 31,\n",
              " 'then': 32,\n",
              " 'ì_': 33,\n",
              " 'no': 34,\n",
              " 'need': 35,\n",
              " 'come': 36,\n",
              " 'again.': 37,\n",
              " 'your': 38,\n",
              " 'friends': 39,\n",
              " 'what': 40,\n",
              " 'plan': 41,\n",
              " 'do': 42,\n",
              " 'on': 43,\n",
              " 'valentines': 44,\n",
              " '@': 45,\n",
              " '&lt;url&gt;': 46,\n",
              " 'same.': 47,\n",
              " 'wana': 48,\n",
              " 'a': 49,\n",
              " 'trip': 50,\n",
              " 'sometme': 51,\n",
              " 'can': 52,\n",
              " 'call': 53,\n",
              " 'me': 54,\n",
              " 'at': 55,\n",
              " '10:10': 56,\n",
              " 'make': 57,\n",
              " 'sure': 58,\n",
              " 'dat': 59,\n",
              " \"i've\": 60,\n",
              " 'woken': 61,\n",
              " 'up...': 62,\n",
              " 'aiyar': 63,\n",
              " 'u': 64,\n",
              " 'so': 65,\n",
              " 'poor': 66,\n",
              " 'thing...': 67,\n",
              " 'i': 68,\n",
              " 'give': 69,\n",
              " 'support': 70,\n",
              " 'k...': 71,\n",
              " 'jia': 72,\n",
              " 'you!': 73,\n",
              " \"i'll\": 74,\n",
              " 'think': 75,\n",
              " 'u...': 76,\n",
              " \"i'm\": 77,\n",
              " 'office': 78,\n",
              " 'now': 79,\n",
              " 'da:)where': 80,\n",
              " 'are': 81,\n",
              " 'you?': 82,\n",
              " 'time': 83,\n",
              " 'finish?': 84,\n",
              " 'am': 85,\n",
              " 'the': 86,\n",
              " 'only': 87,\n",
              " 'one': 88,\n",
              " 'who': 89,\n",
              " \"doesn't\": 90,\n",
              " 'stalk': 91,\n",
              " 'profiles?': 92,\n",
              " 'those': 93,\n",
              " 'were': 94,\n",
              " 'exact': 95,\n",
              " 'intentions': 96,\n",
              " 'check': 97,\n",
              " 'wid': 98,\n",
              " 'corect': 99,\n",
              " 'speling': 100,\n",
              " 'i.e.': 101,\n",
              " 'sarcasm': 102,\n",
              " 'ok': 103,\n",
              " 'lor...': 104,\n",
              " 'hey,': 105,\n",
              " 'guy': 106,\n",
              " 'know': 107,\n",
              " 'is': 108,\n",
              " 'breathing': 109,\n",
              " 'down': 110,\n",
              " 'neck': 111,\n",
              " 'get': 112,\n",
              " 'him': 113,\n",
              " 'some': 114,\n",
              " 'bud,': 115,\n",
              " 'anyway': 116,\n",
              " \"you'd\": 117,\n",
              " 'be': 118,\n",
              " 'able': 119,\n",
              " 'half': 120,\n",
              " 'track': 121,\n",
              " 'usf': 122,\n",
              " 'tonight?': 123,\n",
              " 'freemsg': 124,\n",
              " 'have': 125,\n",
              " 'been': 126,\n",
              " 'awarded': 127,\n",
              " 'free': 128,\n",
              " 'mini': 129,\n",
              " 'digital': 130,\n",
              " 'camera,': 131,\n",
              " 'just': 132,\n",
              " 'reply': 133,\n",
              " 'snap': 134,\n",
              " 'collect': 135,\n",
              " 'prize!': 136,\n",
              " '(quizclub': 137,\n",
              " 'opt': 138,\n",
              " 'out?': 139,\n",
              " 'stop': 140,\n",
              " '80122300p/wk': 141,\n",
              " 'sp:rwm': 142,\n",
              " 'ph:08704050406)': 143,\n",
              " 'will': 144,\n",
              " 'gentle': 145,\n",
              " 'baby!': 146,\n",
              " 'soon': 147,\n",
              " 'taking': 148,\n",
              " 'all': 149,\n",
              " '&lt;#&gt;': 150,\n",
              " 'inches': 151,\n",
              " 'deep': 152,\n",
              " 'inside': 153,\n",
              " 'tight': 154,\n",
              " 'pussy...': 155,\n",
              " 'oh...': 156,\n",
              " 'haha...': 157,\n",
              " 'den': 158,\n",
              " 'we': 159,\n",
              " 'shld': 160,\n",
              " 'had': 161,\n",
              " 'went': 162,\n",
              " 'today': 163,\n",
              " 'too...': 164,\n",
              " 'gee,': 165,\n",
              " 'nvm': 166,\n",
              " 'la...': 167,\n",
              " 'kaiez,': 168,\n",
              " 'dun': 169,\n",
              " 'mind': 170,\n",
              " 'goin': 171,\n",
              " 'jazz': 172,\n",
              " 'oso...': 173,\n",
              " 'scared': 174,\n",
              " 'hiphop': 175,\n",
              " 'open': 176,\n",
              " 'cant': 177,\n",
              " 'catch': 178,\n",
              " 'fantasy': 179,\n",
              " 'football': 180,\n",
              " 'back': 181,\n",
              " 'tv.': 182,\n",
              " 'go': 183,\n",
              " 'sky': 184,\n",
              " 'gamestar': 185,\n",
              " 'active': 186,\n",
              " 'and': 187,\n",
              " 'play': 188,\n",
              " 'å£250k': 189,\n",
              " 'dream': 190,\n",
              " 'team.': 191,\n",
              " 'scoring': 192,\n",
              " 'starts': 193,\n",
              " 'saturday,': 194,\n",
              " 'register': 195,\n",
              " 'now!sky': 196,\n",
              " 'out': 197,\n",
              " '88088': 198,\n",
              " 'thats': 199,\n",
              " 'cool.': 200,\n",
              " 'want': 201,\n",
              " 'please': 202,\n",
              " 'you...': 203,\n",
              " 'yeah': 204,\n",
              " 'totes.': 205,\n",
              " 'when': 206,\n",
              " 'wanna?': 207,\n",
              " 'also': 208,\n",
              " 'doing': 209,\n",
              " 'cbe': 210,\n",
              " 'only.': 211,\n",
              " 'but': 212,\n",
              " 'pay.': 213,\n",
              " 'swt': 214,\n",
              " 'thought:': 215,\n",
              " '\\\\nver': 216,\n",
              " 'tired': 217,\n",
              " 'little': 218,\n",
              " 'things': 219,\n",
              " '4': 220,\n",
              " 'lovable': 221,\n",
              " 'persons..\\\\\"': 222,\n",
              " 'coz..somtimes': 223,\n",
              " 'occupy': 224,\n",
              " 'biggest': 225,\n",
              " 'part': 226,\n",
              " 'their': 227,\n",
              " 'hearts..': 228,\n",
              " 'gud': 229,\n",
              " 'ni8\"': 230,\n",
              " 'why': 231,\n",
              " 'came': 232,\n",
              " 'hostel.': 233,\n",
              " 'somebody': 234,\n",
              " 'should': 235,\n",
              " 'andros': 236,\n",
              " 'steal': 237,\n",
              " 'ice': 238,\n",
              " 'i.ll': 239,\n",
              " 'always': 240,\n",
              " 'there,': 241,\n",
              " 'even': 242,\n",
              " 'if': 243,\n",
              " 'its': 244,\n",
              " 'spirit.': 245,\n",
              " 'bb': 246,\n",
              " 'soon.': 247,\n",
              " 'trying': 248,\n",
              " 'it.': 249,\n",
              " 'ela': 250,\n",
              " 'kano.,il': 251,\n",
              " 'download,': 252,\n",
              " 'wen': 253,\n",
              " 'ur': 254,\n",
              " 'free..': 255,\n",
              " 'hon': 256,\n",
              " 'lab': 257,\n",
              " 'there.': 258,\n",
              " 's.this': 259,\n",
              " 'increase': 260,\n",
              " 'chance': 261,\n",
              " 'winning.': 262,\n",
              " 'ever': 263,\n",
              " 'easier': 264,\n",
              " 'for': 265,\n",
              " \"there'll\": 266,\n",
              " 'minor': 267,\n",
              " 'shindig': 268,\n",
              " 'place': 269,\n",
              " 'later': 270,\n",
              " 'tonight,': 271,\n",
              " 'interested?': 272,\n",
              " \"can't,\": 273,\n",
              " \"don't\": 274,\n",
              " 'her': 275,\n",
              " 'number!': 276,\n",
              " 'aiyo': 277,\n",
              " 'bit': 278,\n",
              " 'pai': 279,\n",
              " 'seh': 280,\n",
              " 'noe...': 281,\n",
              " 'he': 282,\n",
              " 'rem': 283,\n",
              " 'die...': 284,\n",
              " 'hee...': 285,\n",
              " 'become': 286,\n",
              " 'better': 287,\n",
              " 'lookin': 288,\n",
              " 'oredi': 289,\n",
              " 'leh...': 290,\n",
              " 'xy': 291,\n",
              " 'smth': 292,\n",
              " 'now.': 293,\n",
              " 'eat': 294,\n",
              " 'already?': 295,\n",
              " 'havent...': 296,\n",
              " 'good': 297,\n",
              " 'afternoon,': 298,\n",
              " 'boytoy': 299,\n",
              " '...': 300,\n",
              " 'how': 301,\n",
              " 'feeling': 302,\n",
              " '?': 303,\n",
              " 'hope?': 304,\n",
              " 'being': 305,\n",
              " 'boy?': 306,\n",
              " 'obedient,': 307,\n",
              " 'slave?': 308,\n",
              " 'queen?': 309,\n",
              " 'depends': 310,\n",
              " 'quality.': 311,\n",
              " 'type': 312,\n",
              " 'sent': 313,\n",
              " 'boye,': 314,\n",
              " 'faded': 315,\n",
              " 'glory,': 316,\n",
              " 'about': 317,\n",
              " '6.': 318,\n",
              " 'ralphs': 319,\n",
              " 'maybe': 320,\n",
              " '2': 321,\n",
              " 'happen': 322,\n",
              " 'dear.': 323,\n",
              " 'silent.': 324,\n",
              " 'tensed': 325,\n",
              " 'babe,': 326,\n",
              " 'answering': 327,\n",
              " 'you,': 328,\n",
              " \"can't\": 329,\n",
              " 'see': 330,\n",
              " 'reboot': 331,\n",
              " 'ym': 332,\n",
              " 'photo': 333,\n",
              " 'great': 334,\n",
              " '!': 335,\n",
              " 'fuck': 336,\n",
              " 'cedar': 337,\n",
              " 'key': 338,\n",
              " '(come': 339,\n",
              " 'over': 340,\n",
              " 'tho)': 341,\n",
              " 'nope...': 342,\n",
              " 'it': 343,\n",
              " 'monday...': 344,\n",
              " 'sorry': 345,\n",
              " 'replied': 346,\n",
              " 'late': 347,\n",
              " 'keep': 348,\n",
              " 'talking': 349,\n",
              " 'people': 350,\n",
              " 'not': 351,\n",
              " 'pay': 352,\n",
              " 'them': 353,\n",
              " 'they': 354,\n",
              " 'agree': 355,\n",
              " 'price.': 356,\n",
              " 'pls': 357,\n",
              " 'really': 358,\n",
              " 'much': 359,\n",
              " 'willing': 360,\n",
              " 'house-maid': 361,\n",
              " 'murderer,': 362,\n",
              " 'coz': 363,\n",
              " 'man': 364,\n",
              " 'was': 365,\n",
              " 'murdered': 366,\n",
              " 'th': 367,\n",
              " 'january..': 368,\n",
              " 'as': 369,\n",
              " 'public': 370,\n",
              " 'holiday': 371,\n",
              " 'govt.instituitions': 372,\n",
              " 'closed,including': 373,\n",
              " 'post': 374,\n",
              " 'office..': 375,\n",
              " 'o': 376,\n",
              " 'shore': 377,\n",
              " 'takin': 378,\n",
              " 'bus': 379,\n",
              " 'r': 380,\n",
              " 'now?': 381,\n",
              " 'busy': 382,\n",
              " 'wif': 383,\n",
              " 'work?': 384,\n",
              " 'ok...': 385,\n",
              " 'theory': 386,\n",
              " 'test?': 387,\n",
              " 'going': 388,\n",
              " 'book?': 389,\n",
              " '21': 390,\n",
              " 'may.': 391,\n",
              " 'thought': 392,\n",
              " 'wanna': 393,\n",
              " 'with': 394,\n",
              " 'jiayin.': 395,\n",
              " 'she': 396,\n",
              " 'isnt': 397,\n",
              " 'smile': 398,\n",
              " 'hppnss,': 399,\n",
              " 'drop': 400,\n",
              " 'tear': 401,\n",
              " 'sorrow,': 402,\n",
              " 'heart': 403,\n",
              " 'life,': 404,\n",
              " 'like': 405,\n",
              " 'mine': 406,\n",
              " 'wil': 407,\n",
              " 'care': 408,\n",
              " 'u,': 409,\n",
              " 'forevr': 410,\n",
              " 'goodfriend': 411,\n",
              " 'didnt': 412,\n",
              " 'work': 413,\n",
              " 'again': 414,\n",
              " 'oh.': 415,\n",
              " 'goodnight': 416,\n",
              " 'then.': 417,\n",
              " 'fix': 418,\n",
              " 'ready': 419,\n",
              " 'by': 420,\n",
              " 'wake': 421,\n",
              " 'up.': 422,\n",
              " 'very': 423,\n",
              " 'dearly': 424,\n",
              " 'missed': 425,\n",
              " 'night': 426,\n",
              " 'sleep.': 427,\n",
              " 'staying': 428,\n",
              " 'prolly': 429,\n",
              " \"won't\": 430,\n",
              " 'til': 431,\n",
              " 'here': 432,\n",
              " 'discount': 433,\n",
              " 'code': 434,\n",
              " 'rp176781.': 435,\n",
              " 'further': 436,\n",
              " 'messages': 437,\n",
              " 'stop.': 438,\n",
              " 'www.regalportfolio.co.uk.': 439,\n",
              " 'customer': 440,\n",
              " 'services': 441,\n",
              " '08717205546': 442,\n",
              " 'yes.': 443,\n",
              " 'nigh': 444,\n",
              " 'aha.': 445,\n",
              " 'å£400': 446,\n",
              " 'xmas': 447,\n",
              " 'reward': 448,\n",
              " 'waiting': 449,\n",
              " 'our': 450,\n",
              " 'computer': 451,\n",
              " 'has': 452,\n",
              " 'randomly': 453,\n",
              " 'picked': 454,\n",
              " 'from': 455,\n",
              " 'loyal': 456,\n",
              " 'mobile': 457,\n",
              " 'customers': 458,\n",
              " 'receive': 459,\n",
              " 'reward.': 460,\n",
              " '09066380611': 461,\n",
              " 'ended': 462,\n",
              " 'another': 463,\n",
              " 'day,': 464,\n",
              " 'morning': 465,\n",
              " 'special': 466,\n",
              " 'way.': 467,\n",
              " 'may': 468,\n",
              " 'sunny': 469,\n",
              " 'rays': 470,\n",
              " 'leaves': 471,\n",
              " 'worries': 472,\n",
              " 'blue': 473,\n",
              " 'bay.': 474,\n",
              " 'mrng': 475,\n",
              " 'might': 476,\n",
              " 'kerala': 477,\n",
              " 'days.so': 478,\n",
              " 'prepared': 479,\n",
              " 'take': 480,\n",
              " 'leave': 481,\n",
              " 'once': 482,\n",
              " 'finalise': 483,\n",
              " '.dont': 484,\n",
              " 'any': 485,\n",
              " 'travel': 486,\n",
              " 'during': 487,\n",
              " 'visit.need': 488,\n",
              " 'finish': 489,\n",
              " 'urgent': 490,\n",
              " 'works.': 491,\n",
              " 'hi': 492,\n",
              " 'princess!': 493,\n",
              " 'thank': 494,\n",
              " 'pics.': 495,\n",
              " 'pretty.': 496,\n",
              " 'cancelled': 497,\n",
              " 'well': 498,\n",
              " 'that': 499,\n",
              " 'sounds': 500,\n",
              " 'important': 501,\n",
              " 'understand': 502,\n",
              " 'darlin': 503,\n",
              " 'ring': 504,\n",
              " 'this': 505,\n",
              " 'fone': 506,\n",
              " 'love': 507,\n",
              " 'kate': 508,\n",
              " 'x': 509,\n",
              " 'cool,': 510,\n",
              " 'text': 511,\n",
              " 'few': 512,\n",
              " 'yep': 513,\n",
              " 'program.': 514,\n",
              " \"you're\": 515,\n",
              " 'slacking.': 516,\n",
              " '(bank': 517,\n",
              " 'granite': 518,\n",
              " 'issues': 519,\n",
              " 'strong-buy)': 520,\n",
              " 'explosive': 521,\n",
              " 'pick': 522,\n",
              " 'members': 523,\n",
              " '*****up': 524,\n",
              " '300%': 525,\n",
              " '***********': 526,\n",
              " 'nasdaq': 527,\n",
              " 'symbol': 528,\n",
              " 'cdgt': 529,\n",
              " '$5.00': 530,\n",
              " 'per..': 531,\n",
              " 'meant': 532,\n",
              " 'say': 533,\n",
              " 'wait': 534,\n",
              " 'getting': 535,\n",
              " 'bored': 536,\n",
              " 'bridgwater': 537,\n",
              " 'banter': 538,\n",
              " 'off,': 539,\n",
              " 'call,': 540,\n",
              " 'phones': 541,\n",
              " 'having': 542,\n",
              " 'problems': 543,\n",
              " 'dont': 544,\n",
              " 'so.': 545,\n",
              " 'turns': 546,\n",
              " 'off': 547,\n",
              " 'randomlly': 548,\n",
              " 'within': 549,\n",
              " '5min': 550,\n",
              " 'opening': 551,\n",
              " 'driving...': 552,\n",
              " 'raining!': 553,\n",
              " 'caught': 554,\n",
              " 'e': 555,\n",
              " 'mrt': 556,\n",
              " 'station': 557,\n",
              " 'lor.': 558,\n",
              " 'accidentally': 559,\n",
              " 'deleted': 560,\n",
              " 'message.': 561,\n",
              " 'resend': 562,\n",
              " 'please.': 563,\n",
              " 'height': 564,\n",
              " '\\\\oh': 565,\n",
              " 'shit....!!\\\\\"': 566,\n",
              " 'situation:': 567,\n",
              " 'throws': 568,\n",
              " 'luv': 569,\n",
              " 'letter': 570,\n",
              " 'gal': 571,\n",
              " 'falls': 572,\n",
              " 'brothers': 573,\n",
              " 'head': 574,\n",
              " 'whos': 575,\n",
              " 'gay': 576,\n",
              " 'shoot': 577,\n",
              " 'me.': 578,\n",
              " 'docs': 579,\n",
              " 'room.': 580,\n",
              " 'nuerologist.': 581,\n",
              " 'valentine': 582,\n",
              " 'game.': 583,\n",
              " '.': 584,\n",
              " 'send': 585,\n",
              " 'dis': 586,\n",
              " 'msg': 587,\n",
              " 'friends.': 588,\n",
              " '..': 589,\n",
              " '5': 590,\n",
              " 'answers': 591,\n",
              " 'same': 592,\n",
              " 'someone': 593,\n",
              " 'loves': 594,\n",
              " 'u.': 595,\n",
              " 'ques-': 596,\n",
              " 'which': 597,\n",
              " 'colour': 598,\n",
              " 'suits': 599,\n",
              " 'best?rply': 600,\n",
              " '\\\\petey': 601,\n",
              " 'boy': 602,\n",
              " 'whereare': 603,\n",
              " 'friendsare': 604,\n",
              " 'thekingshead': 605,\n",
              " 'canlove': 606,\n",
              " 'nic\\\\\"\"': 607,\n",
              " 'congrats': 608,\n",
              " '3g': 609,\n",
              " 'videophones': 610,\n",
              " 'yours.': 611,\n",
              " '09063458130': 612,\n",
              " 'now!': 613,\n",
              " 'videochat': 614,\n",
              " 'mates,': 615,\n",
              " 'java': 616,\n",
              " 'games,': 617,\n",
              " 'dload': 618,\n",
              " 'polyph': 619,\n",
              " 'music,': 620,\n",
              " 'noline': 621,\n",
              " 'rentl.': 622,\n",
              " 'bx420.': 623,\n",
              " 'ip4.': 624,\n",
              " '5we.': 625,\n",
              " '150p': 626,\n",
              " 'it\\x89û÷s': 627,\n",
              " 'reassuring,': 628,\n",
              " 'crazy': 629,\n",
              " 'world.': 630,\n",
              " 'log': 631,\n",
              " 'wat.': 632,\n",
              " 'sdryb8i': 633,\n",
              " 'said': 634,\n",
              " 'gonna': 635,\n",
              " 'snow,': 636,\n",
              " 'start': 637,\n",
              " 'around': 638,\n",
              " '8': 639,\n",
              " '9': 640,\n",
              " 'pm': 641,\n",
              " 'tonite!': 642,\n",
              " 'predicting': 643,\n",
              " 'an': 644,\n",
              " 'inch': 645,\n",
              " 'accumulation.': 646,\n",
              " 'year.': 647,\n",
              " 'miles.': 648,\n",
              " 'reminder:': 649,\n",
              " 'downloaded': 650,\n",
              " 'content': 651,\n",
              " 'already': 652,\n",
              " 'paid': 653,\n",
              " 'for.': 654,\n",
              " 'goto': 655,\n",
              " 'http://doit.': 656,\n",
              " 'mymoby.': 657,\n",
              " 'tv/': 658,\n",
              " 'content.': 659,\n",
              " 'aight': 660,\n",
              " 'still': 661,\n",
              " 'money': 662,\n",
              " 'does': 663,\n",
              " 'simple': 664,\n",
              " 'arithmetic': 665,\n",
              " 'percentages.': 666,\n",
              " 'creepy': 667,\n",
              " 'late.': 668,\n",
              " 'there': 669,\n",
              " 'well.': 670,\n",
              " 'balls.': 671,\n",
              " 'calls': 672,\n",
              " 'she.s': 673,\n",
              " 'good.': 674,\n",
              " 'wondering': 675,\n",
              " 'wont': 676,\n",
              " 'smiling': 677,\n",
              " 'coping': 678,\n",
              " 'long': 679,\n",
              " 'distance': 680,\n",
              " 'girls': 681,\n",
              " 'safe': 682,\n",
              " 'selfish': 683,\n",
              " 'pa.': 684,\n",
              " 'you.': 685,\n",
              " 'night.': 686,\n",
              " 'realise': 687,\n",
              " 'bother.': 688,\n",
              " 'exams': 689,\n",
              " 'outta': 690,\n",
              " 'way': 691,\n",
              " 'try': 692,\n",
              " 'cars.': 693,\n",
              " 'gr8': 694,\n",
              " 'yo,': 695,\n",
              " 'around?': 696,\n",
              " 'car': 697,\n",
              " 'bad': 698,\n",
              " 'girl.': 699,\n",
              " 'remember': 700,\n",
              " 'cuz': 701,\n",
              " 'ibored.': 702,\n",
              " 'don': 703,\n",
              " 'study': 704,\n",
              " 'mm': 705,\n",
              " 'yes': 706,\n",
              " 'look': 707,\n",
              " 'hugging': 708,\n",
              " 'both.': 709,\n",
              " ':-p': 710,\n",
              " 'g.w.r': 711,\n",
              " 'stuff': 712,\n",
              " 'sell': 713,\n",
              " 'laid': 714,\n",
              " 'airtel': 715,\n",
              " 'line': 716,\n",
              " 'rest?': 717,\n",
              " 'set': 718,\n",
              " 'mind,': 719,\n",
              " 'easily': 720,\n",
              " 'forgets': 721,\n",
              " 'remember.': 722,\n",
              " 'wish': 723,\n",
              " 'day!': 724,\n",
              " 'weeks': 725,\n",
              " 'savamob': 726,\n",
              " 'member': 727,\n",
              " 'offers': 728,\n",
              " 'accessible.': 729,\n",
              " '08709501522': 730,\n",
              " 'details!': 731,\n",
              " 'savamob,': 732,\n",
              " 'pobox': 733,\n",
              " '139,': 734,\n",
              " 'la3': 735,\n",
              " '2wu.': 736,\n",
              " 'å£1.50/week.': 737,\n",
              " '-': 738,\n",
              " 'mobile!': 739,\n",
              " 'spatula': 740,\n",
              " 'hands!': 741,\n",
              " \"'an\": 742,\n",
              " 'amazing': 743,\n",
              " \"quote''\": 744,\n",
              " '\\\\sometimes': 745,\n",
              " 'life': 746,\n",
              " 'difficult': 747,\n",
              " 'decide': 748,\n",
              " 'whats': 749,\n",
              " 'wrong!!': 750,\n",
              " 'lie': 751,\n",
              " 'brings': 752,\n",
              " 'truth': 753,\n",
              " 'tear....\\\\\"\"': 754,\n",
              " 'yar': 755,\n",
              " 'raining': 756,\n",
              " 'non': 757,\n",
              " 'stop...': 758,\n",
              " 'wan': 759,\n",
              " 'elsewhere?': 760,\n",
              " 'well,': 761,\n",
              " 'opposed': 762,\n",
              " 'drunken': 763,\n",
              " 'before': 764,\n",
              " 'ok.': 765,\n",
              " 'making': 766,\n",
              " 'money.': 767,\n",
              " 'then,': 768,\n",
              " 'depressed': 769,\n",
              " 'sittin': 770,\n",
              " 'waitin': 771,\n",
              " 'phone': 772,\n",
              " 'ring...': 773,\n",
              " 'hope': 774,\n",
              " 'wind': 775,\n",
              " 'drops': 776,\n",
              " 'though,': 777,\n",
              " 'scary': 778,\n",
              " 'quite': 779,\n",
              " 'do.': 780,\n",
              " 'hold': 781,\n",
              " 'anyone.': 782,\n",
              " 'cud': 783,\n",
              " 'up': 784,\n",
              " 'bout': 785,\n",
              " '7.30pm': 786,\n",
              " \"they're\": 787,\n",
              " 'pub?': 788,\n",
              " 'much,': 789,\n",
              " \"textin'.\": 790,\n",
              " 'romcapspam': 791,\n",
              " 'everyone': 792,\n",
              " 'responding': 793,\n",
              " 'presence': 794,\n",
              " 'since': 795,\n",
              " 'warm': 796,\n",
              " 'outgoing.': 797,\n",
              " 'bringing': 798,\n",
              " 'real': 799,\n",
              " 'breath': 800,\n",
              " 'sunshine.': 801,\n",
              " '88066': 802,\n",
              " 'lost': 803,\n",
              " '3pound': 804,\n",
              " 'help': 805,\n",
              " 'chance,': 806,\n",
              " 'friend': 807,\n",
              " 'wanted': 808,\n",
              " 'ask': 809,\n",
              " 'big': 810,\n",
              " 'order': 811,\n",
              " 'surprised': 812,\n",
              " 'guess': 813,\n",
              " 'right': 814,\n",
              " 'all,': 815,\n",
              " 'loving': 816,\n",
              " 'gopalettan.': 817,\n",
              " 'planning': 818,\n",
              " 'small': 819,\n",
              " 'gift': 820,\n",
              " 'day.': 821,\n",
              " 'participate': 822,\n",
              " 'welcome.': 823,\n",
              " 'contact': 824,\n",
              " 'admin': 825,\n",
              " 'team': 826,\n",
              " 'more': 827,\n",
              " 'details': 828,\n",
              " 'plz': 829,\n",
              " 'ans.': 830,\n",
              " 'bslvyl': 831,\n",
              " 'via': 832,\n",
              " 'fullonsms.com': 833,\n",
              " 'new': 834,\n",
              " 'year': 835,\n",
              " 'tomorrow': 836,\n",
              " 'å£6': 837,\n",
              " 'in,': 838,\n",
              " 'ok?': 839,\n",
              " 'ride': 840,\n",
              " 'when,': 841,\n",
              " 'side,': 842,\n",
              " 'fever,': 843,\n",
              " 'vomitin.': 844,\n",
              " 'hoping': 845,\n",
              " 'away': 846,\n",
              " '7,': 847,\n",
              " 'langport.': 848,\n",
              " 'town': 849,\n",
              " 'did': 850,\n",
              " 'bitching': 851,\n",
              " 'acted': 852,\n",
              " \"i'd\": 853,\n",
              " 'interested': 854,\n",
              " 'buying': 855,\n",
              " 'something': 856,\n",
              " 'else': 857,\n",
              " 'next': 858,\n",
              " 'week': 859,\n",
              " 'gave': 860,\n",
              " 'freemsg>fav': 861,\n",
              " 'tones!reply': 862,\n",
              " 'urgh,': 863,\n",
              " 'coach': 864,\n",
              " 'hot,': 865,\n",
              " 'smells': 866,\n",
              " 'chip': 867,\n",
              " 'fat!': 868,\n",
              " 'thanks': 869,\n",
              " 'again,': 870,\n",
              " 'especially': 871,\n",
              " 'duvet': 872,\n",
              " '(not': 873,\n",
              " 'predictive': 874,\n",
              " 'word).': 875,\n",
              " 'result.': 876,\n",
              " 'eyes': 877,\n",
              " 'philosophy': 878,\n",
              " 'feel': 879,\n",
              " 'kadeem': 880,\n",
              " 'again?': 881,\n",
              " ':v': 882,\n",
              " 'printed': 883,\n",
              " 'upstairs': 884,\n",
              " 'worry.': 885,\n",
              " \"you'll\": 886,\n",
              " 'aight,': 887,\n",
              " 'close': 888,\n",
              " 'gotta': 889,\n",
              " 'after': 890,\n",
              " 'thx.': 891,\n",
              " 'months': 892,\n",
              " 'hey': 893,\n",
              " 'power': 894,\n",
              " 'yoga': 895,\n",
              " 'hip': 896,\n",
              " 'hop': 897,\n",
              " 'kb': 898,\n",
              " 'yogasana': 899,\n",
              " 'dumb?': 900,\n",
              " 'sorry,': 901,\n",
              " 'later.': 902,\n",
              " 'meeting': 903,\n",
              " 'sir.': 904,\n",
              " 'both': 905,\n",
              " 'days.': 906,\n",
              " 'dinner': 907,\n",
              " 'tonite?': 908,\n",
              " 'invited?': 909,\n",
              " 'shijutta...........': 910,\n",
              " '&amp;': 911,\n",
              " 'successful': 912,\n",
              " 'rs': 913,\n",
              " 'da:)do': 914,\n",
              " 'it?': 915,\n",
              " 'ran': 916,\n",
              " 'younger': 917,\n",
              " 'man.': 918,\n",
              " 'pretty': 919,\n",
              " 'babies': 920,\n",
              " 'together': 921,\n",
              " ':)': 922,\n",
              " '2nd': 923,\n",
              " 'attempt': 924,\n",
              " 'å£900': 925,\n",
              " 'prize': 926,\n",
              " 'yesterday': 927,\n",
              " 'awaiting': 928,\n",
              " 'collection.': 929,\n",
              " 'claim': 930,\n",
              " '09061702893.': 931,\n",
              " 'acl03530150pm': 932,\n",
              " 'number': 933,\n",
              " 'forgot': 934,\n",
              " 'city': 935,\n",
              " 'break': 936,\n",
              " 'could': 937,\n",
              " 'win': 938,\n",
              " 'å£200': 939,\n",
              " 'summer': 940,\n",
              " 'shopping': 941,\n",
              " 'spree': 942,\n",
              " 'every': 943,\n",
              " 'wk.': 944,\n",
              " 'txt': 945,\n",
              " 'store': 946,\n",
              " '88039': 947,\n",
              " 'skilgme.': 948,\n",
              " 'tscs087147403231winawk!age16': 949,\n",
              " 'å£1.50perwksub': 950,\n",
              " 'nights...we': 951,\n",
              " 'nt': 952,\n",
              " 'port': 953,\n",
              " 'step': 954,\n",
              " 'liao...too': 955,\n",
              " 'ex': 956,\n",
              " 'dude': 957,\n",
              " 'haircut.': 958,\n",
              " 'breezy': 959,\n",
              " 'battery': 960,\n",
              " 'died,': 961,\n",
              " 'senthil': 962,\n",
              " 'group': 963,\n",
              " 'company': 964,\n",
              " 'apnt': 965,\n",
              " '5pm.': 966,\n",
              " 'receiving': 967,\n",
              " \"week's\": 968,\n",
              " 'triple': 969,\n",
              " 'echo': 970,\n",
              " 'ringtone': 971,\n",
              " 'shortly.': 972,\n",
              " 'enjoy': 973,\n",
              " 'it!': 974,\n",
              " 'spoke': 975,\n",
              " 'uncle': 976,\n",
              " 'john': 977,\n",
              " 'today.': 978,\n",
              " 'strongly': 979,\n",
              " 'feels': 980,\n",
              " 'sacrifice': 981,\n",
              " 'here.': 982,\n",
              " \"he's\": 983,\n",
              " 'does,': 984,\n",
              " 'beg': 985,\n",
              " 'listen.': 986,\n",
              " 'promises': 987,\n",
              " 'clear': 988,\n",
              " 'easy.': 989,\n",
              " 'let': 990,\n",
              " 'out.': 991,\n",
              " 'expecting': 992,\n",
              " 'help,': 993,\n",
              " 'creativity': 994,\n",
              " 'stifled': 995,\n",
              " 'happy,': 996,\n",
              " 'part.': 997,\n",
              " '&': 998,\n",
              " 'meet': 999,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(word2idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4GhZ_NQ4gwF",
        "outputId": "164f0690-0041-4d0a-980f-9f844b4b0e21"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10542"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert data into word indices\n",
        "# note: could have done this on the fly earlier\n",
        "train_sentences_as_int = []\n",
        "for i, row in df_train.iterrows():\n",
        "    tokens = row['data'].lower().split()\n",
        "    sentence_as_int = [word2idx[token] for token in tokens]\n",
        "    train_sentences_as_int.append(sentence_as_int)"
      ],
      "metadata": {
        "id": "aL8j4BiQ4lHA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences_as_int = []\n",
        "for i, row in df_test.iterrows():\n",
        "    tokens = row['data'].lower().split()\n",
        "    sentence_as_int = [word2idx[token] for token in tokens if token in word2idx]\n",
        "    test_sentences_as_int.append(sentence_as_int)"
      ],
      "metadata": {
        "id": "F7Fdw16E5adb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_sentences_as_int), len(test_sentences_as_int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8GojZEY5wXW",
        "outputId": "3a763122-7135-4ccd-94d2-26f593ffff0f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3733, 1839)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_generator(X, y, batch_size=32):\n",
        "    X,y = shuffle(X, y)\n",
        "    n_batches = int(np.ceil(len(y) / batch_size))\n",
        "    for i in range(n_batches):\n",
        "        end = min((i+1)*batch_size, len(y))\n",
        "\n",
        "        X_batch = X[i*batch_size:end]\n",
        "        y_batch = y[i*batch_size:end]\n",
        "\n",
        "        # pad X_batch to be N x T\n",
        "        max_len = max(len(x) for x in X_batch)\n",
        "        for j in range(len(X_batch)):\n",
        "            x = X_batch[j]\n",
        "            pad = [0] * (max_len - len(x))\n",
        "            X_batch[j] = x + pad\n",
        "\n",
        "        # convert to tensors\n",
        "        X_batch = torch.from_numpy(np.array(X_batch)).long()\n",
        "        y_batch = torch.from_numpy(np.array(y_batch)).long()\n",
        "\n",
        "        yield X_batch, y_batch"
      ],
      "metadata": {
        "id": "nKClF33K5wse"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, targets in data_generator(train_sentences_as_int, df_train.b_labels):\n",
        "    print(\"inputs:\", inputs, \"shape:\", inputs.shape)\n",
        "    print(\"targets:\", targets, \"shape:\", targets.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvEJzXkq71eJ",
        "outputId": "09c65977-8d83-412a-f109-96f782c2370e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs: tensor([[  68,  392,  853,  ...,    0,    0,    0],\n",
            "        [ 534,  584,   68,  ...,    0,    0,    0],\n",
            "        [  68,  201,  114,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [1011, 2067,   28,  ...,    0,    0,    0],\n",
            "        [ 253,  254,  221,  ...,    0,    0,    0],\n",
            "        [ 660,  144, 1240,  ...,    0,    0,    0]]) shape: torch.Size([32, 49])\n",
            "targets: tensor([0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
            "        0, 0, 0, 1, 0, 1, 0, 0]) shape: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, targets in data_generator(test_sentences_as_int, df_test.b_labels):\n",
        "    print(\"inputs:\", inputs, \"shape:\", inputs.shape)\n",
        "    print(\"targets:\", targets, \"shape:\", targets.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DeTPD7d8OLG",
        "outputId": "30fc91d4-4c9e-4108-d654-375abdac6c23"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs: tensor([[   74,  1459,   118,   638,  5029,    49,  1790,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0],\n",
            "        [   68,   132,  3119,   114,    65,   544,   125,   499,  2395,  2937,\n",
            "          1415,     3,   201,   343,     6,    86,  1199,   467,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0],\n",
            "        [  297,    39,   408,   265,  3023,   888,    39,   502,  3023,   187,\n",
            "          3995,    39,  1856,  5243,  7325,  7325,  1095,   229,  1911,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0],\n",
            "        [   16,  1775,  6087,    28,   930,   505,   725,  6088,    55,     3,\n",
            "          2934,   202,   183,    28,  6089,  1370,  4512,    28,   140,  4440,\n",
            "           945,   140,    28,  9755,     0,     0,     0,     0,     0,     0,\n",
            "             0],\n",
            "        [ 7831,   177,  2761,     3,   934,    15,  4583,   584,  1463,    69,\n",
            "            64,    49,   244,  6401,   187,   394,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0],\n",
            "        [   64,   555,  4185,    37,  2254,   555, 10408,  1006,    12,   254,\n",
            "          1042,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0],\n",
            "        [  208,   700,    28,   112,  3010,   455,    38,   697,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0],\n",
            "        [  901,    74,    53,   270,     4,  4486,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0],\n",
            "        [ 1411,    36,   340,  1381,   144,   118,   432,   147,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0],\n",
            "        [   68,   177,   522,    86,   772,   814,   293,   357,   585,    49,\n",
            "          1238,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0],\n",
            "        [  893,   380,    33,   661,  6869,    60,  1176,    86,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0],\n",
            "        [   68,   774,    38,  6758,  4331,    68,  2309,   499,     3,   476,\n",
            "           125,  3000,    49,   278,   206,     3,    86,  2581,   365,    49,\n",
            "           303,    68,    85,   432,   449,   206,     3,    36,  5339,    15,\n",
            "           507],\n",
            "        [ 8861,  4319,   144,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0],\n",
            "        [ 1748,    28,   118,    68,    85,    68,   340,   243,    77,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0],\n",
            "        [  351,   119,    28,    42,  1837,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0],\n",
            "        [  345,    15,  9909,  2477,   343,   103,   243,    68,    36,   420,\n",
            "           381,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0],\n",
            "        [ 4346,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0],\n",
            "        [   74,   990,     3,   107,   206,   343,  7641,     4,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0],\n",
            "        [ 1436,    64,   759,    54,   321,   183,   707,   220,  3616,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0],\n",
            "        [ 4058,   243,    68,   112,   644,   455,     3,   499,     1,   187,\n",
            "          6709,  7523,    28,  7890,    49, 10044,  5809,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0],\n",
            "        [ 4951,   265,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0],\n",
            "        [   52,    49,  7696,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0],\n",
            "        [ 1475,  5771,   212,   244,   351,    49, 10074,   697,   432,    65,\n",
            "           244,   287,    28,    29,   455,  3594,     6,     6,   243,    68,\n",
            "          1001,   343,  3224,  9336,   239,  4757,     0,     0,     0,     0,\n",
            "             0],\n",
            "        [  905,   922,    68,   577,   810,  6442,    65,   112,  3344,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0],\n",
            "        [  163,   108,  3149,  3150,  3149,    54,  3151,  2838,  3152,  3153,\n",
            "          3154,  3155,  3156,  3157,  3158,  3159,  3160,  3161,  3162,  3163,\n",
            "            34,  3164,  2113,  3165,     0,     0,     0,     0,     0,     0,\n",
            "             0],\n",
            "        [ 4407,   103,    68,   183,  1352,   707,    55,    86,    32,    68,\n",
            "           587,    33,  6591,  5722,   388,    28,  2102,    43,   923,   468,\n",
            "          1501,   212,   275,  1639,   108,    55,     0,     0,     0,     0,\n",
            "             0],\n",
            "        [  159,    81,  5556,    28,  7651,   499,    38,  4490,   265,   715,\n",
            "           108,    38,   144,   322,   549,  2489,   906,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0],\n",
            "        [ 1463,    53,     3,  4833,  1463,   114,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0],\n",
            "        [   86,  1352,    12,  7450,   973,   249,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0],\n",
            "        [ 1515,   301,   108,    49,   919,  5906,   405,     3,  5062,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0],\n",
            "        [   68,  2988,   206,   396,   663,  4131,   396,   546,    40,   235,\n",
            "           118,    49,  2561,   941,    50,  1234,   644,  7871,    14,    12,\n",
            "           301,  1345,  1415,   707,     4,   275,  1035,     0,     0,     0,\n",
            "             0],\n",
            "        [  187,    81,  1561,   293,   274,  1113,    86,  6400,  2107,    53,\n",
            "            55,   321,   140,  3973,    53,  4386,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0]]) shape: torch.Size([32, 31])\n",
            "targets: tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 1]) shape: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tad7LMt98YPz",
        "outputId": "25bc1d4a-9ebc-42db-ee21-ef5014975217"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, n_vocab, embed_dim, hidden_size, n_rnn_layers, n_outputs):\n",
        "        super(RNN, self).__init__()\n",
        "        self.V = n_vocab\n",
        "        self.D = embed_dim\n",
        "        self.M = hidden_size\n",
        "        self.K = n_outputs\n",
        "        self.L = n_rnn_layers\n",
        "\n",
        "        self.embed = nn.Embedding(self.V, self.D)\n",
        "        self.rnn = nn.LSTM(\n",
        "            input_size=self.D,\n",
        "            hidden_size=self.M,\n",
        "            num_layers=self.L,\n",
        "            batch_first=True,\n",
        "        )\n",
        "        self.fc = nn.Linear(self.M, self.K)\n",
        "\n",
        "    def forward(self, X):\n",
        "        # initial hidden states\n",
        "        h0 = torch.zeros(self.L, X.size(0), self.M).to(device)\n",
        "        c0 = torch.zeros(self.L, X.size(0), self.M).to(device)\n",
        "        \n",
        "        # embedding layer\n",
        "        # turns word indexes into word vectors\n",
        "        out = self.embed(X)\n",
        "\n",
        "        # get RNN unit output\n",
        "        out, _ = self.rnn(out, (h0, c0))\n",
        "\n",
        "        # max pool\n",
        "        out, _ = torch.max(out, 1)\n",
        "\n",
        "        # we only want h(T) at the final time step\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "bxy5b2Ei8eMF"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RNN(len(word2idx), 20, 15, 1, 1)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYxidkP7_nej",
        "outputId": "433fd263-78bb-48d6-a750-64b2462579da"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(\n",
              "  (embed): Embedding(10542, 20)\n",
              "  (rnn): LSTM(20, 15, batch_first=True)\n",
              "  (fc): Linear(in_features=15, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "PEZMv6OWASa4"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_gen = lambda: data_generator(train_sentences_as_int, df_train.b_labels)\n",
        "test_gen = lambda: data_generator(test_sentences_as_int, df_test.b_labels)"
      ],
      "metadata": {
        "id": "RnbLYEadAZF8"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A function to encapsulate the training loop\n",
        "def batch_gd(model, criterion, optimizer, epochs):\n",
        "    train_losses = np.zeros(epochs)\n",
        "    test_losses = np.zeros(epochs)\n",
        "\n",
        "    for it in range(epochs):\n",
        "        t0 = datetime.now()\n",
        "        train_loss = []\n",
        "        for inputs, targets in train_gen():\n",
        "            # print(\"inputs.shape\", inputs.shape, \"targets.shape\", targets.shape)\n",
        "            targets = targets.view(-1, 1).float()\n",
        "            # move data to GPU\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            # backward and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss.append(loss.item())\n",
        "\n",
        "        # Get train loss and test accuracy\n",
        "        train_loss = np.mean(train_loss) # a little misleading \n",
        "\n",
        "        test_loss = []\n",
        "        for inputs, targets in test_gen():\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            targets = targets.view(-1, 1).float()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            test_loss.append(loss.item())\n",
        "        test_loss = np.mean(test_loss)\n",
        "\n",
        "        # Save losses\n",
        "        train_losses[it] = train_loss\n",
        "        test_losses[it] = test_loss\n",
        "\n",
        "        dt = datetime.now() - t0\n",
        "        print(f\"Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Duration: {dt}\")\n",
        "\n",
        "    return train_losses, test_losses"
      ],
      "metadata": {
        "id": "HgA5z_m7Arqm"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses, test_losses = batch_gd(model, criterion, optimizer, 15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biv95rlpC4PN",
        "outputId": "c88db544-5a8d-40c9-f01d-4b1e36f7f2ab"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15, Train Loss: 0.5584, Test Loss: 0.4260, Duration: 0:00:01.708240\n",
            "Epoch 2/15, Train Loss: 0.4017, Test Loss: 0.3795, Duration: 0:00:01.453261\n",
            "Epoch 3/15, Train Loss: 0.3768, Test Loss: 0.3558, Duration: 0:00:01.395962\n",
            "Epoch 4/15, Train Loss: 0.3480, Test Loss: 0.3085, Duration: 0:00:01.296858\n",
            "Epoch 5/15, Train Loss: 0.2733, Test Loss: 0.2190, Duration: 0:00:01.305241\n",
            "Epoch 6/15, Train Loss: 0.1848, Test Loss: 0.1622, Duration: 0:00:01.302263\n",
            "Epoch 7/15, Train Loss: 0.1598, Test Loss: 0.1449, Duration: 0:00:01.283398\n",
            "Epoch 8/15, Train Loss: 0.1131, Test Loss: 0.1150, Duration: 0:00:01.256619\n",
            "Epoch 9/15, Train Loss: 0.0942, Test Loss: 0.1136, Duration: 0:00:01.304654\n",
            "Epoch 10/15, Train Loss: 0.0801, Test Loss: 0.1091, Duration: 0:00:01.279433\n",
            "Epoch 11/15, Train Loss: 0.0705, Test Loss: 0.1080, Duration: 0:00:01.267404\n",
            "Epoch 12/15, Train Loss: 0.0641, Test Loss: 0.1000, Duration: 0:00:01.277387\n",
            "Epoch 13/15, Train Loss: 0.0591, Test Loss: 0.1095, Duration: 0:00:01.293375\n",
            "Epoch 14/15, Train Loss: 0.0545, Test Loss: 0.0980, Duration: 0:00:01.325248\n",
            "Epoch 15/15, Train Loss: 0.0465, Test Loss: 0.0961, Duration: 0:00:01.299755\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the train loss and test loss per iteration\n",
        "plt.plot(train_losses, label='train loss')\n",
        "plt.plot(test_losses, label='test loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "w-pCeQ6gC9F2",
        "outputId": "888f84fc-06aa-479a-c0b1-95b171198e04"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy\n",
        "n_correct = 0.\n",
        "n_total = 0.\n",
        "for inputs, targets in train_gen():\n",
        "    targets = targets.view(-1, 1).float()\n",
        "    inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "    # forward pass\n",
        "    outputs = model(inputs)\n",
        "    \n",
        "    # get predictions\n",
        "    predictions = (outputs > 0).float()\n",
        "\n",
        "    # update counts\n",
        "    n_correct += (predictions == targets).sum().item()\n",
        "    n_total += targets.shape[0]\n",
        "\n",
        "train_acc = n_correct / n_total\n",
        "\n",
        "n_correct = 0.\n",
        "n_total = 0.\n",
        "for inputs, targets in test_gen():\n",
        "    targets = targets.view(-1, 1).float()\n",
        "    inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "    # forward pass\n",
        "    outputs = model(inputs)\n",
        "    \n",
        "    # get predictions\n",
        "    predictions = (outputs > 0).float()\n",
        "\n",
        "    # update counts\n",
        "    n_correct += (predictions == targets).sum().item()\n",
        "    n_total += targets.shape[0]\n",
        "\n",
        "test_acc = n_correct / n_total\n",
        "print(f\"Train acc: {train_acc:.4f}, Test acc: {test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlwHU9QMDa7-",
        "outputId": "6d5ac91e-bb43-499f-f320-0dcff800cd24"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train acc: 0.9898, Test acc: 0.9766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A-8l-eoLFd6D"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}